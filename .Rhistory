dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
View(test_df)
View(train_df)
View(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
dt
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
View(data_test)
library(randomForest)
View(data_test)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
rfm
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
Y
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i) }
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
}
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
print(accuracy_vec)
max(accuracy_vec)
pred <- predict(model, newdata=test_df)
m2 <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=10)
pred <- predict(m2, newdata=test_df)
accuracy_vec
target_variable <- ncol(train_df)
mtry <- 10
ntree <- 300
train_idx <- sample(1:nrow(train_df))
max <- ceiling(nrow(train_df)/10)
splits <- split(train_idx, ceiling(seq_along(train_idx)/max))
cv_accuracy <- array(0,10)
for (cv in 1:10){
test_data <- train_df[splits[[cv]],]
train_data <- train_df[sample(-splits[[cv]]),]
model <- randomForest(x=train_data[,-c(target_variable)],
y=train_data[,c(target_variable)],
xtest=test_data[,-c(target_variable)],
ytest=test_data[,c(target_variable)],
ntree=ntree,mtry=mtry)
cv_accuracy[cv] = (model$test$confusion[1,1]+model$test$confusion[2,2]+model$test$confusion[3,3])/sum(model$test$confusion)
print(paste("Accuracy Score of the -",cv,"fold = ",cv_accuracy[cv]))
}
for (cv in 1:10){
test_data <- train_df[splits[[cv]],]
train_data <- train_df[sample(-splits[[cv]]),]
model <- randomForest(x=train_data[,-c(target_variable)],
y=train_data[,c(target_variable)],
xtest=test_data[,-c(target_variable)],
ytest=test_data[,c(target_variable)],
ntree=ntree,mtry=mtry)
cv_accuracy[cv] = (model$test$confusion[1,1]+model$test$confusion[2,2]+model$test$confusion[3,3])/sum(model$test$confusion)
print(paste("Accuracy Score of the -",cv,"fold = ",cv_accuracy[cv]))
}
print(paste('Mean accuracy score for ntree = 300 and mtry = 10 : ',mean(cv_accuracy)))
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
target_variable <- ncol(train_df)
mtry <- 10
ntree <- 300
train_idx <- sample(1:nrow(train_df))
max <- ceiling(nrow(train_df)/10)
splits <- split(train_idx, ceiling(seq_along(train_idx)/max))
cv_accuracy <- array(0,10)
for (cv in 1:10){
test_data <- train_df[splits[[cv]],]
train_data <- train_df[sample(-splits[[cv]]),]
model <- randomForest(x=train_data[,-c(target_variable)],
y=train_data[,c(target_variable)],
xtest=test_data[,-c(target_variable)],
ytest=test_data[,c(target_variable)],
ntree=ntree,mtry=mtry)
cv_accuracy[cv] = (model$test$confusion[1,1]+model$test$confusion[2,2]+model$test$confusion[3,3])/sum(model$test$confusion)
print(paste("Accuracy Score of the -",cv,"fold = ",cv_accuracy[cv]))
}
ntree <- 10
for (cv in 1:10){
test_data <- train_df[splits[[cv]],]
train_data <- train_df[sample(-splits[[cv]]),]
model <- randomForest(x=train_data[,-c(target_variable)],
y=train_data[,c(target_variable)],
xtest=test_data[,-c(target_variable)],
ytest=test_data[,c(target_variable)],
ntree=ntree,mtry=mtry)
cv_accuracy[cv] = (model$test$confusion[1,1]+model$test$confusion[2,2]+model$test$confusion[3,3])/sum(model$test$confusion)
print(paste("Accuracy Score of the -",cv,"fold = ",cv_accuracy[cv]))
}
300
300
ntree <- 300
train_idx <- sample(1:nrow(train_df))
max <- ceiling(nrow(train_df)/10)
splits <- split(train_idx, ceiling(seq_along(train_idx)/max))
cv_accuracy <- array(0,10)
for (cv in 1:10){
test_data <- train_df[splits[[cv]],]
train_data <- train_df[sample(-splits[[cv]]),]
model <- randomForest(x=train_data[,-c(target_variable)],
y=train_data[,c(target_variable)],
xtest=test_data[,-c(target_variable)],
ytest=test_data[,c(target_variable)],
ntree=ntree,mtry=mtry)
cv_accuracy[cv] = (model$test$confusion[1,1]+model$test$confusion[2,2]+model$test$confusion[3,3])/sum(model$test$confusion)
print(paste("Accuracy Score of the -",cv,"fold = ",cv_accuracy[cv]))
}
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=13)
Y_pred <- predict(rfmm,test_df)
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
View(df)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=13)
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
View(df)
which.max(accuracy_vec)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec))
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
which.max(accuracy_vec)
View(df)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec))
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
View(df)
which.max(accuracy_vec)
accuracy_vec
View(df)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec))
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
View(df)
View(test)
df$id <- test$ID
View(df)
df <- data.frame(pred)
View(df)
cbind(test$ID,df$pred)
final_sub <- cbind(test$ID,df$pred)
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv", row.names = FALSE)
accuracy_vec
max(accuracy_vec)
