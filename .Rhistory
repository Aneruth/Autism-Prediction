library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=5)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
# Hyper parameter tuning for random forest
accuracy_vec <- array(0,15)
for (i in 1:16){
model <- randomForest(x=data_train[,-16],
y=as.factor(data_train[,16]),
xtest=data_test[,-16],
ytest=as.factor(data_test[,16]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
return(accuracy_vec) # Hyper parameter tuned scores in a vector
}
accuracy_vec <- randomForest()
randomForest()
# Random Forest
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=5)
# Reading the dataset
train_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/train.csv")
test_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/test.csv")
train_df$Class.ASD <- as.factor(train_df$Class.ASD)
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','used_app_before','relation','age_desc')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train_df)
test_df <- clean_dataset(test_df)
labels_rename <- function(dataset){
# Factorizing the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorizing the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
# Factorizing the jaundice label where yes is 0 and no is 1
dataset$austim <- ifelse(dataset$austim == "yes",as.numeric(0),dataset$austim)
dataset$austim <- ifelse(dataset$austim == "no",as.numeric(1),dataset$austim)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
# Splitting the dataset into train test with 80:20 ratio
dt = sort(sample(nrow(train_df), nrow(train_df)*.75))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
# Random Forest
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
pred <- predict(rfm,test_df)
df <- data.frame(pred)
final_sub <- data.frame(test$ID,df$pred)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
final_sub <- data.frame(test$ID,df$pred)
# Renaming the columns
names(final_sub)[1] <- "ID"
names(final_sub)[2] <- "Class/ASD"
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Sub_data/rf_sub_intro.csv", row.names = FALSE)
hyperPara <- function(){
accuracy_vec <- array(0,16)
for (i in 1:16){
model <- randomForest(x=data_train[,-16],
y=as.factor(data_train[,16]),
xtest=data_test[,-16],
ytest=as.factor(data_test[,16]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
print(accuracy_vec)
}
hyperPara
hyperPara
hyperPara()
which.max(accuracy_vec)
accuracy_vec = hyperPara()
hyperPara <- function(){
accuracy_vec <- array(0,16)
for (i in 1:16){
model <- randomForest(x=data_train[,-16],
y=as.factor(data_train[,16]),
xtest=data_test[,-16],
ytest=as.factor(data_test[,16]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
return(accuracy_vec)
}
accuracy_vec = hyperPara()
which.max(accuracy_vec)
accuracy_vec[12]
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec),
importance = TRUE,
proximity = TRUE)
pr <- predict(rfmm,test_df)
table(pr,Y)
table(Y_pred,Y)
sum(diag(table(pr,Y))/sum(table(pr,Y)))
train_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/train.csv")
test_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/test.csv")
id <- test_df$ID
train_df$Class.ASD <- as.factor(train_df$Class.ASD)
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','contry_of_res','used_app_before','relation','age_desc')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train_df)
test_df <- clean_dataset(test_df)
View(train_df)
train_df <- renameEthinicity(train_df)
renameEthinicity <- function(dataset){
dataset$ethnicity <- ifelse(dataset$ethnicity == "?","Others",dataset$ethnicity)
return(dataset)
}
train_df <- renameEthinicity(train_df)
test_df <- renameEthinicity(test_df)
library(superml)
install.packages("superml")
library(superml)
as.numeric(train_df$ethnicity)
as.numeric(factor(train_df$ethnicity))
for (cols in names(train_df)) {
print(typeof(train_df$col))
}
for (cols in names(train_df)) {
print(type(train_df$col))
}
sapply(train_df, class)
length(unique(train_df$jaundice))
typeof(train_df$austim)
function(train_df)
function(train_df)
function(train_df)
function(train_df)
encodeDataset <- function(dataset){
for (cols in names(dataset)) {
if (length(unique(dataset$col)) >= 2 & typeof(dataset$col) == "character"){
print(cols)
}
}
}
function(train_df)
encodeDataset(train_df)
encodeDataset <- function(dataset){
for (cols in names(dataset)) {
if (length(unique(dataset$col)) >= 2){
print(cols)
}
}
}
encodeDataset(train_df)
encodeDataset <- function(dataset){
for (cols in names(dataset)) {
if (length(unique(dataset$cols)) >= 2){
print(cols)
}
}
}
encodeDataset(train_df)
encodeDataset <- function(dataset){
for (cols in names(dataset)) {
# if (length(unique(dataset$cols)) >= 2){
#   print(cols)
# }
print(cols)
}
}
encodeDataset(train_df)
}
encodeDataset <- function(dataset){
for (cols in names(dataset)) {
# if (length(unique(dataset$cols)) >= 2){
#   print(cols)
# }
print(length(unique(dataset$cols)))
}
}
encodeDataset(train_df)
encodeDataset <- function(dataset){
for (cols in names(dataset)) {
# if (length(unique(dataset$cols)) >= 2){
#   print(cols)
# }
print(unique(dataset$cols))
}
}
encodeDataset(train_df)
names(train_df)
vector(names(train_df))
type(names(train_df))
typeof(names(train_df))
names(train_df)
encodeDataset <- function(dataset){
dataset$age <- as.numeric(factor(dataset$age))
dataset$gender <- as.numeric(factor(dataset$gender))
dataset$ethnicity <- as.numeric(factor(dataset$ethnicity))
dataset$jaundice <- as.numeric(factor(dataset$jaundice))
dataset$austim <- as.numeric(factor(dataset$austim))
return(dataset)
}
View(encodeDataset(train_df))
train_df <- encodeDataset(train_df)
test_df <- encodeDataset(test_df)
dt = sort(sample(nrow(train_df), nrow(train_df)*.75))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(e1071)
set.seed(120)  # Setting Seed
classifier_cl <- naiveBayes(Class.ASD ~ ., data = data_train)
classifier_cl
y_pred <- predict(classifier_cl, test_df)
# Confusion Matrix
cm <- table(test_df, y_pred)
Y <- data_test[,ncol(data_test)]
# Confusion Matrix
cm <- table(y_pred, Y)
cm
length(y_pred)
sum(diag(cm)/sum(cm))
sub_4 <- data.frame(y_pred)
sub_4 <- data.frame(id,sub_4$y_pred)
# Renaming the columns
names(sub_4)[1] <- "ID"
names(sub_4)[2] <- "Class/ASD"
write.csv(sub_4,"~/Documents/GitHub/Autism-Prediction/Sub_data/NB_sub_2.csv", row.names = FALSE)
train_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/train.csv")
test_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/test.csv")
id <- test_df$ID
train_df$Class.ASD <- as.factor(train_df$Class.ASD)
View(train_df)
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','age_desc')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train_df)
test_df <- clean_dataset(test_df)
renameEthinicity <- function(dataset){
dataset$ethnicity <- ifelse(dataset$ethnicity == "?","Others",dataset$ethnicity)
return(dataset)
}
train_df <- renameEthinicity(train_df)
test_df <- renameEthinicity(test_df)
encodeDataset <- function(dataset){
dataset$used_app_before <- as.numeric(factor(dataset$used_app_before))
dataset$age <- as.numeric(factor(dataset$age))
dataset$gender <- as.numeric(factor(dataset$gender))
dataset$ethnicity <- as.numeric(factor(dataset$ethnicity))
dataset$jaundice <- as.numeric(factor(dataset$jaundice))
dataset$austim <- as.numeric(factor(dataset$austim))
return(dataset)
}
train_df <- encodeDataset(train_df)
test_df <- encodeDataset(test_df)
train_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/train.csv")
test_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/test.csv")
id <- test_df$ID
train_df$Class.ASD <- as.factor(train_df$Class.ASD)
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','age_desc')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train_df)
test_df <- clean_dataset(test_df)
renameEthinicity <- function(dataset){
dataset$ethnicity <- ifelse(dataset$ethnicity == "?","Others",dataset$ethnicity)
return(dataset)
}
train_df <- renameEthinicity(train_df)
test_df <- renameEthinicity(test_df)
encodeDataset <- function(dataset){
dataset$used_app_before <- as.numeric(factor(dataset$used_app_before))
dataset$contry_of_res <- as.numeric((factor(dataset$contry_of_res)))
dataset$relation <- as.numeric((factor(dataset$relation)))
dataset$age <- as.numeric(factor(dataset$age))
dataset$gender <- as.numeric(factor(dataset$gender))
dataset$ethnicity <- as.numeric(factor(dataset$ethnicity))
dataset$jaundice <- as.numeric(factor(dataset$jaundice))
dataset$austim <- as.numeric(factor(dataset$austim))
return(dataset)
}
train_df <- encodeDataset(train_df)
test_df <- encodeDataset(test_df)
dt = sort(sample(nrow(train_df), nrow(train_df)*.75))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(e1071)
set.seed(1120)  # Setting Seed
classifier_cl <- naiveBayes(Class.ASD ~ ., data = data_train)
classifier_cl
y_pred <- predict(classifier_cl, test_df)
Y <- data_test[,ncol(data_test)]
# Confusion Matrix
cm <- table(y_pred, Y)
cm
sum(diag(cm))/sum(cm)
sub_4 <- data.frame(y_pred)
sub_4 <- data.frame(id,sub_4$y_pred)
# Renaming the columns
names(sub_4)[1] <- "ID"
names(sub_4)[2] <- "Class/ASD"
write.csv(sub_4,"~/Documents/GitHub/Autism-Prediction/Sub_data/NB_sub_3.csv", row.names = FALSE)
dim(train_df)
dim(train_df)[1]
dim(train_df)[2]
dim(data_train)[2]
randomForest <- function(){
# Package for random forest
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
# Hyper parameter tuning for random forest
accuracy_vec <- array(0,dim(data_train)[2])
for (i in 1:dim(data_train)[2]){
model <- randomForest(x=data_train[,-dim(data_train)[2]],
y=as.factor(data_train[,dim(data_train)[2]]),
xtest=data_test[,-dim(data_train)[2]],
ytest=as.factor(data_test[,dim(data_train)[2]]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
return(accuracy_vec) # Hyper parameter tuned scores in a vector
}
accuracy_vec <- randomForest()
# Package for random forest
library(randomForest)
randomForest <- function(){
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
# Hyper parameter tuning for random forest
accuracy_vec <- array(0,dim(data_train)[2])
for (i in 1:dim(data_train)[2]){
model <- randomForest(x=data_train[,-dim(data_train)[2]],
y=as.factor(data_train[,dim(data_train)[2]]),
xtest=data_test[,-dim(data_train)[2]],
ytest=as.factor(data_test[,dim(data_train)[2]]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
return(accuracy_vec) # Hyper parameter tuned scores in a vector
}
accuracy_vec <- randomForest()
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
glm()
write.csv(test_df,"~/Documents/test.csv", row.names = FALSE)
write.csv(train_df,"~/Documents/train.csv", row.names = FALSE)
train_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/train.csv")
test_df <- read.csv("~/Documents/GitHub/Autism-Prediction/Data/test.csv")
id <- test_df$ID
train_df$Class.ASD <- as.factor(train_df$Class.ASD)
View(test_df)
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','age_desc','gender','relation','used_app_before','jaundice')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train_df)
test_df <- clean_dataset(test_df)
renameEthinicity <- function(dataset){
dataset$ethnicity <- ifelse(dataset$ethnicity == "?","Others",dataset$ethnicity)
return(dataset)
}
train_df <- renameEthinicity(train_df)
test_df <- renameEthinicity(test_df)
encodeDataset <- function(dataset){
dataset$contry_of_res <- as.numeric((factor(dataset$contry_of_res)))
dataset$ethnicity <- as.numeric(factor(dataset$ethnicity))
dataset$austim <- as.numeric(factor(dataset$austim))
return(dataset)
}
train_df <- encodeDataset(train_df)
test_df <- encodeDataset(test_df)
dt = sort(sample(nrow(train_df), nrow(train_df)*.75))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(e1071)
set.seed(20)  # Setting Seed
classifier_cl <- naiveBayes(Class.ASD ~ ., data = data_train)
classifier_cl
y_pred <- predict(classifier_cl, test_df)
Y <- data_test[,ncol(data_test)]
# Confusion Matrix
cm <- table(y_pred, Y)
cm
sub_4 <- data.frame(y_pred)
sub_4 <- data.frame(id,sub_4$y_pred)
# Renaming the columns
names(sub_4)[1] <- "ID"
names(sub_4)[2] <- "Class/ASD"
write.csv(sub_4,"~/Documents/GitHub/Autism-Prediction/Sub_data/NB_sub_4.csv", row.names = FALSE)
test <- read.csv('/Users/aneruthmohanasundaram/Desktop/train_data.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
View(train)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('/Users/aneruthmohanasundaram/Desktop/train_data.csv')
View(train)
train <- read.csv('/Users/aneruthmohanasundaram/Desktop/train_data.csv')
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('/Users/aneruthmohanasundaram/Desktop/train_data.csv')
train$Class.ASD <- as.factor(train$Class.ASD)
test <- read.csv('/Users/aneruthmohanasundaram/Desktop/test_data.csv')
train <- read.csv('/Users/aneruthmohanasundaram/Desktop/train_data.csv')
train$Class.ASD <- as.factor(train$Class.ASD)
# Splitting the dataset into train test with 80:20 ratio
dt = sort(sample(nrow(train), nrow(train_df)*.8))
# Splitting the dataset into train test with 80:20 ratio
dt = sort(sample(nrow(train), nrow(train)*.8))
data_train<-train[dt,]
data_test<-train[-dt,]
randomForest <- function(){
# Package for random forest
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
}
randomForest()
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
test <- read.csv('/Users/aneruthmohanasundaram/Desktop/test_data.csv')
train <- read.csv('/Users/aneruthmohanasundaram/Desktop/train_data.csv')
# Splitting the dataset into train test with 80:20 ratio
dt = sort(sample(nrow(train), nrow(train)*.8))
data_train<-train[dt,]
data_test<-train[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
test <- read.csv('/Users/aneruthmohanasundaram/Desktop/test_data.csv')
train <- read.csv('/Users/aneruthmohanasundaram/Desktop/train_data.csv')
train$Class.ASD <- as.factor(train$Class.ASD)
# Splitting the dataset into train test with 80:20 ratio
dt = sort(sample(nrow(train), nrow(train)*.8))
data_train<-train[dt,]
data_test<-train[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
ndim(data_train)
dim(data_train)
dim(data_train)[2]
accuracy_vec <- array(0,dim(data_train)[2])
for (i in 1:dim(data_train)[2]){
model <- randomForest(x=data_train[,-dim(data_train)[2]],
y=as.factor(data_train[,dim(data_train)[2]]),
xtest=data_test[,-dim(data_train)[2]],
ytest=as.factor(data_test[,dim(data_train)[2]]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
