print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec))
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
View(df)
which.max(accuracy_vec)
accuracy_vec
View(df)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorising the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorising the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec))
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
View(df)
View(test)
df$id <- test$ID
View(df)
df <- data.frame(pred)
View(df)
cbind(test$ID,df$pred)
final_sub <- cbind(test$ID,df$pred)
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv", row.names = FALSE)
accuracy_vec
max(accuracy_vec)
View(test_df)
View(train_df)
dim(data_test)
dim(data_train)
library(caret)
set.seed(123)
train_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train_df.csv')
test_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test_df.csv')
lab <- train_data$Class.ASD
mtry <- sqrt(ncol(train_data))
tunegrid <- expand.grid(.mtry=mtry)
mod <- train(Class.ASD ~ ., data = train_data, method = "rf",
trControl = trainControl(method = "LGOCV", p = 0.8, number = 1,
savePredictions = T))
mod$pred
help(caret)
??caret
set.seed(123)
train_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train_df.csv')
test_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test_df.csv')
X <- train_data[,1:14]
y <- train_data[,15]
library(randomForest)
rfm = randomForest(data = data_train,ntree=100)
rfm = randomForest(data =X,ntree=100)
rfm = randomForest(y,data =X,ntree=100)
rfm = randomForest(Class.ASD~.,data = train_data,ntree=100)
Y_pred <- predict(rfm,test_data[,-ncol(test_data)])
set.seed(123)
train_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train_df.csv')
test_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test_df.csv')
library(randomForest)
model = randomForest(Class.ASD~.,data = train_data,ntree=100, mtry = 5)
View(model)
model$confusion
predict(model, newdata = test_data)
predict <- predict(model, newdata = test_data)
table(prediction, test$taste)
table(predict, test$taste)
table(predict, test_data$taste)
table(predict, train_data$Class.ASD)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorizing the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorizing the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec))
pred <- predict(rfmm,test_df, "prob")
df <- data.frame(pred)
final_sub <- cbind(test$ID,df$pred)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorizing the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorizing the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec))
pred <- predict(rfmm,test_df, "prob")
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorizing the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorizing the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
write.csv(train_df,"~/Documents/GitHub/Autism-Prediction/Data/train_df.csv", row.names = FALSE)
write.csv(test_df,"~/Documents/GitHub/Autism-Prediction/Data/test_df.csv", row.names = FALSE)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,importance = TRUE,proximity = TRUE)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec),
importance = TRUE,
proximity = TRUE)
pred <- predict(rfmm,test_df, "prob")
df <- data.frame(pred)
train_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train_df.csv')
test_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test_df.csv')
library(randomForest)
model = randomForest(Class.ASD~.,data = train_data,ntree=100, mtry = 5,
importance = TRUE,
proximity = TRUE)
predict <- predict(model, newdata = test_data.'prob')
predict <- predict(model, newdata = test_data,'prob')
predict <- predict(model, newdata = test_data,predict.all=TRUE)
table(predict, train_data$Class.ASD)
View(predict)
model = randomForest(Class.ASD~.,data = train_data,ntree=100, mtry = 5,
proximity = TRUE)
set.seed(123)
train_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train_df.csv')
test_data <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test_df.csv')
train_data$Class.ASD <- as.factor(train_data$Class.ASD)
View(train_data)
library(randomForest)
model = randomForest(Class.ASD~.,data = train_data,ntree=100, mtry = 5,
proximity = TRUE)
predict <- predict(model, newdata = test_data)
table(predict, train_data$Class.ASD)
data.frame(predict)
cnf_mat <- table(predict,train_data$Class.ASD)
predict <- predict(model, newdata = train_data$Class.ASD)
predict <- predict(model, newdata = train_data)
cnf_mat <- table(predict,train_data$Class.ASD)
sum(diag(cnf_mat)/sum(cnf_mat))
predict <- predict(model, newdata = test_data)
cnf_mat <- table(predict,test_data)
predict <- predict(model, newdata = test_data,'prob')
df <- data.frame(predict)
View(df)
predict <- predict(model, newdata = test_data)
df <- data.frame(predict)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
final_sub <- cbind(test$ID,df$pred)
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv", row.names = FALSE)
View(read.csv('~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv'))
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv", row.names = T)
View(read.csv('~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv'))
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv", row.names = FALSE)
View(read.csv('~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv'))
final_sub
data.frame(cbind(test$ID,df$pred))
data.frame(cbind(test$ID,df$pred),c('ID','Class/ASD'))
names(final_sub)
View(final_sub)
names(final_sub)[1] <- "ID"
names(final_sub)[2] <- "Class/ASD"
View(final_sub)
names(final_sub)
data.frame(test$ID,df$pred)
check <- data.frame(test$ID,df$pred)
names(data.frame(test$ID,df$pred))
data.frame(test$ID,df$pred,c('ID','Class/ASD'))
final_sub <- data.frame(test$ID,df$pred)
final_sub$test.ID = "ID"
names(final_sub)
names(final_sub)[1]
names(final_sub)[1] <- "ID"
names(final_sub)[2] <- "Class/ASD"
final_sub
View(final_sub)
final_sub$ID <- test$ID
View(final_sub)
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Data/final_sub.csv", row.names = FALSE)
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train_data$Class.ASD <- as.factor(train$Class.ASD)
train_dim <- dim(train) # Dimensions of the train dataset
test <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/test.csv')
train <- read.csv('~/Documents/GitHub/Autism-Prediction/Data/train.csv')
train$Class.ASD <- as.factor(train$Class.ASD)
train_dim <- dim(train) # Dimensions of the train dataset
print(train_dim)
test_dim <- dim(test) # Dimensions of the test dataset
print(test_dim)
head(data.frame(train$age_desc))
# We can say that the columns consist of only one unique value so we might not need it
train <- train[ , !names(train) %in% c('age_desc')]
# Doing the same for test dataset
test <- test[ , !names(test) %in% c('age_desc')]
# Printing the dimensions after reducing the columns
dim(train)
dim(test)
# After analyzing the dataset we can say that column ID,ethnicity,country_res,autism,used_app and relation not required for prediction
clean_dataset <- function(dataset) {
col_to_remove <- c('ID','ethnicity','contry_of_res','austim','used_app_before','relation')
for (col in col_to_remove) {
dataset <- dataset[ , !names(dataset) %in% c(col)]
}
return(dataset)
}
train_df <- clean_dataset(train)
test_df <- clean_dataset(test)
labels_rename <- function(dataset){
# Factorizing the gender label where male is 0 and female is 1
dataset$gender <- ifelse(dataset$gender == "m",as.numeric(0),dataset$gender)
dataset$gender <- ifelse(dataset$gender == "f",as.numeric(1),dataset$gender)
# Factorizing the jaundice label where yes is 0 and no is 1
dataset$jaundice <- ifelse(dataset$jaundice == "yes",as.numeric(0),dataset$jaundice)
dataset$jaundice <- ifelse(dataset$jaundice == "no",as.numeric(1),dataset$jaundice)
return(dataset)
}
train_df <- labels_rename(train_df)
test_df <- labels_rename(test_df)
dt = sort(sample(nrow(train_df), nrow(train_df)*.8))
data_train<-train_df[dt,]
data_test<-train_df[-dt,]
library(randomForest)
rfm = randomForest(Class.ASD~.,data = data_train,ntree=100,proximity = TRUE)
Y_pred <- predict(rfm,data_test[,-ncol(data_test)])
Y <- data_test[,ncol(data_test)]
# Building the confusion matrix
confusion_matrix <- table(Y_pred,Y)
confusion_matrix
accuracy_randomForest = sum(diag(confusion_matrix)/sum(confusion_matrix))
paste0('Accuracy Score for random forest using train test split : ',round(accuracy_randomForest*100),'%')
accuracy_vec <- array(0,15)
for (i in 1:15){
model <- randomForest(x=data_train[,-15],
y=as.factor(data_train[,15]),
xtest=data_test[,-15],
ytest=as.factor(data_test[,15]),
ntree=i,
importance = TRUE,
proximity = TRUE)
accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)
}
accuracy_vec
rfmm = randomForest(Class.ASD~.,data = data_train,ntree=which.max(accuracy_vec),
importance = TRUE,
proximity = TRUE)
pred <- predict(rfmm,test_df)
df <- data.frame(pred)
View(df)
final_sub <- data.frame(test$ID,df$pred)
# Renaming the columns
final_sub$test.ID <- "ID"
View(final_sub)
final_sub <- data.frame(test$ID,df$pred)
names(final_sub)
names(final_sub)[1] <- "ID"
names(final_sub)[2] <- "Class/ASD"
write.csv(final_sub,"~/Documents/GitHub/Autism-Prediction/Data/final_sub_2.csv", row.names = FALSE)
